{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"/home/martin/Documents/git/GNN/torch_geometric_examples/\") \n",
    "# custom dataset\n",
    "from division_v import DivisionV\n",
    "from division import Division\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "PATH = '/home/martin/graphs/division'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating splits: train: 0:80, valid: 81:91, test: 92:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset   = DivisionV(PATH, split='train')\n",
    "val_dataset     = DivisionV(PATH, split='val')\n",
    "test_dataset    = DivisionV(PATH, split='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "#train_dataset[0].num_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(train_dataset.num_features, 256, heads=4, edge_dim=1)\n",
    "        self.lin1 = torch.nn.Linear(train_dataset.num_features, 4 * 256)\n",
    "        self.conv2 = GATConv(4 * 256, 256, heads=4, edge_dim=1)\n",
    "        self.lin2 = torch.nn.Linear(4 * 256, 4 * 256)\n",
    "        self.conv3 = GATConv(4 * 256, 1, heads=6,\n",
    "                             concat=False, edge_dim=1)\n",
    "        self.lin3 = torch.nn.Linear(4 * 256, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = F.relu(self.conv1(x, edge_index) + self.lin1(x))\n",
    "        x = F.relu(self.conv2(x, edge_index) + self.lin2(x))\n",
    "        x = self.conv3(x, edge_index) + self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "loss_op = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─GATConv: 1-1                           --\n",
      "|    └─Linear: 2-1                       1,024\n",
      "|    └─Linear: 2-2                       1,024\n",
      "├─Linear: 1-2                            2,048\n",
      "├─GATConv: 1-3                           --\n",
      "|    └─Linear: 2-3                       1,048,576\n",
      "|    └─Linear: 2-4                       1,024\n",
      "├─Linear: 1-4                            1,049,600\n",
      "├─GATConv: 1-5                           --\n",
      "|    └─Linear: 2-5                       6,144\n",
      "|    └─Linear: 2-6                       6\n",
      "├─Linear: 1-6                            1,025\n",
      "=================================================================\n",
      "Total params: 2,110,471\n",
      "Trainable params: 2,110,471\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "su = summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "\n",
    "        data = data[0]\n",
    "        \n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        rt = model(data.x, data.edge_index, data.edge_attr)\n",
    "        loss = loss_op(rt, data.y)\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for epoch in range(1, 1001):\n",
    "    loss = train()\n",
    "    # val_f1 = test(val_loader)\n",
    "    # test_f1 = test(test_loader)\n",
    "    # print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_f1:.4f}, '\n",
    "    #       f'Test: {test_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60001963]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.058615923"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = 8\n",
    "DS = 0\n",
    "model.eval()\n",
    "out = model(test_dataset[DS][0].x.to(device), test_dataset[DS][0].edge_index.to(device), test_dataset[DS][0].edge_attr)\n",
    "print(test_dataset[DS][0].x.numpy()[ID])\n",
    "out.cpu().detach().numpy()[ID][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.214478164816683e-07"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43eec52ae2e25fdee062f41bc35729fb531c177f05340703a5c1c13e281532e7"
  },
  "kernelspec": {
   "display_name": "Python [conda env:torch-pyg]",
   "language": "python",
   "name": "conda-env-torch-pyg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
